{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Giving more power to LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # installing libraries\n",
    "\n",
    "# !pip install langchain\n",
    "# !pip install openai\n",
    "# !pip install PyPDF2\n",
    "# !pip install faiss-cpu\n",
    "# !pip install tiktoken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 1. Installing Libraries\n",
    "\n",
    "```python\n",
    "# Installing the LangChain library for managing chains of actions with language models\n",
    "!pip install langchain\n",
    "```\n",
    "**LangChain**: This library helps in chaining together various components (like language models, tools, and data sources) to create complex language-based applications.\n",
    "\n",
    "```python\n",
    "# Installing the OpenAI library for accessing OpenAI's language models\n",
    "!pip install openai\n",
    "```\n",
    "**OpenAI**: This library is used to interact with OpenAI's language models (like GPT-3.5), which will be used for generating answers based on the PDF content.\n",
    "\n",
    "```python\n",
    "# Installing the PyPDF2 library for reading and extracting text from PDF files\n",
    "!pip install PyPDF2\n",
    "```\n",
    "**PyPDF2**: This library allows you to read and extract text from PDF files. It will be used to process the PDF document and obtain the text content for further analysis.\n",
    "\n",
    "```python\n",
    "# Installing the Faiss library for efficient similarity search and clustering of dense vectors\n",
    "!pip install faiss-cpu\n",
    "```\n",
    "**Faiss**: This library, developed by Facebook AI Research, is used for efficient similarity search. It helps in quickly finding similar text passages or chunks from the PDF by comparing vector representations.\n",
    "\n",
    "```python\n",
    "# Installing the tiktoken library for tokenization\n",
    "!pip install tiktoken\n",
    "```\n",
    "**Tiktoken**: This library helps in efficiently tokenizing text, which is necessary for processing text with language models and for vectorization.\n",
    "\n",
    "### Summary of the Workflow\n",
    "\n",
    "1. **Extract Text from PDF**: Use PyPDF2 to read and extract text from the provided PDF document.\n",
    "2. **Text Processing and Vectorization**: Tokenize the extracted text and convert it into vector representations using Tiktoken.\n",
    "3. **Indexing for Fast Retrieval**: Use Faiss to index these vectors, enabling efficient similarity search.\n",
    "4. **Question Answering**: Utilize OpenAI's language models to answer questions by referencing the indexed text chunks.\n",
    "\n",
    "### High-Level Steps\n",
    "\n",
    "1. **Extract Text**:\n",
    "   ```python\n",
    "   import PyPDF2\n",
    "   \n",
    "   def extract_text_from_pdf(pdf_path):\n",
    "       with open(pdf_path, 'rb') as file:\n",
    "           reader = PyPDF2.PdfFileReader(file)\n",
    "           text = ''\n",
    "           for page_num in range(reader.numPages):\n",
    "               text += reader.getPage(page_num).extract_text()\n",
    "       return text\n",
    "   ```\n",
    "\n",
    "2. **Tokenize and Vectorize**:\n",
    "   ```python\n",
    "   from tiktoken import Tokenizer\n",
    "   \n",
    "   tokenizer = Tokenizer()\n",
    "   text = extract_text_from_pdf('example.pdf')\n",
    "   tokens = tokenizer.tokenize(text)\n",
    "   ```\n",
    "\n",
    "3. **Indexing**:\n",
    "   ```python\n",
    "   import faiss\n",
    "   import numpy as np\n",
    "   \n",
    "   # Assuming 'embeddings' is a list of vector representations of text chunks\n",
    "   index = faiss.IndexFlatL2(len(embeddings[0]))\n",
    "   index.add(np.array(embeddings))\n",
    "   ```\n",
    "\n",
    "4. **Answering Questions**:\n",
    "   ```python\n",
    "   import openai\n",
    "   \n",
    "   def answer_question(question, index, embeddings, text_chunks):\n",
    "       # Find the closest text chunks using Faiss\n",
    "       question_embedding = embed_question(question)  # Function to convert question to vector\n",
    "       _, indices = index.search(np.array([question_embedding]), k=5)\n",
    "       \n",
    "       # Combine the text from the closest chunks\n",
    "       context = ' '.join([text_chunks[i] for i in indices[0]])\n",
    "       \n",
    "       # Use OpenAI to generate an answer\n",
    "       response = openai.Completion.create(\n",
    "           model=\"text-davinci-003\",\n",
    "           prompt=f\"Answer the question based on the following context:\\n\\n{context}\\n\\nQuestion: {question}\",\n",
    "           max_tokens=150\n",
    "       )\n",
    "       return response.choices[0].text.strip()\n",
    "   ```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import classes from libraries\n",
    "\n",
    "from PyPDF import pdfReader\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_split"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
